{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Corpus creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# files = glob.glob(os.path.join(\"data\", '*.csv'))\n",
    "# print(files)\n",
    "movie_reviews = 'data\\\\tamil_movie_reviews_train.csv'\n",
    "news = 'data\\\\tamil_news_train.csv'\n",
    "thirukural = 'data\\\\tamil_thirukkural_train.csv'\n",
    "\n",
    "corpus = \"\"\n",
    "\n",
    "movie_reviews_df = pd.read_csv(movie_reviews)\n",
    "for index, row in movie_reviews_df.iterrows():\n",
    "    corpus += \"\\n\" + row['ReviewInTamil']\n",
    "\n",
    "news_df = pd.read_csv(news)\n",
    "for index, row in news_df.iterrows():\n",
    "    corpus += \"\\n\" + row['NewsInTamil']\n",
    "\n",
    "thirukural_df = pd.read_csv(thirukural)\n",
    "for index, row in thirukural_df.iterrows():\n",
    "    corpus += \"\\n\" + row['kural'] + \" \" + row['mk']  + \" \" +   row['mv']  + \" \" + row['sp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the corpus to a file\n",
    "with open(os.path.join(\"data\", 'corpus.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentencePiece based BPE tokenizer for Tamil   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/google/sentencepiece/blob/master/doc/options.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a sentencepiece model on it\n",
    "import os\n",
    "\n",
    "options = dict(\n",
    "  # input spec\n",
    "  input=\"data/corpus.txt\",\n",
    "  input_format=\"text\",\n",
    "  # output spec\n",
    "  model_prefix=\"Tamil10k_BPE\", # output filename prefix\n",
    "  # algorithm spec\n",
    "  # BPE alg\n",
    "  model_type=\"bpe\",\n",
    "  vocab_size=10000,\n",
    "  # normalization\n",
    "  normalization_rule_name=\"identity\", # ew, turn off normalization\n",
    "  remove_extra_whitespaces=False,\n",
    "  input_sentence_size=150136, # max number of training sentences\n",
    "  max_sentence_length=4192, # max number of bytes per sentence\n",
    "  seed_sentencepiece_size=1000000, \n",
    "  shuffle_input_sentence=True,\n",
    "  # rare word treatment\n",
    "  character_coverage=0.99995,\n",
    "  byte_fallback=True,\n",
    "  # merge rules\n",
    "  split_digits=True,\n",
    "  split_by_unicode_script=True,\n",
    "  split_by_whitespace=True,\n",
    "  split_by_number=True,\n",
    "  max_sentencepiece_length=16,\n",
    "  add_dummy_prefix=True,\n",
    "  allow_whitespace_only_pieces=True,\n",
    "  # special tokens\n",
    "  unk_id=0, # the UNK token MUST exist\n",
    "  bos_id=1, # the others are optional, set to -1 to turn off\n",
    "  eos_id=2,\n",
    "  pad_id=-1,\n",
    "  # systems\n",
    "  num_threads=os.cpu_count(), # use ~all system resources\n",
    ")\n",
    "\n",
    "spm.SentencePieceTrainer.train(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('Tamil10k_BPE.model')\n",
    "vocab = [[sp.id_to_piece(idx), idx] for idx in range(sp.get_piece_size())]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150136"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "original_vocab_size = len(\" \".join(corpus).split(\" \"))\n",
    "original_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0136"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_ratio = original_vocab_size / len(vocab)\n",
    "compression_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1592, 5773, 1339, 1171, 696, 2111]\n"
     ]
    }
   ],
   "source": [
    "ids = sp.encode(\"தமிழ் மொழி பற்றி அறிந்து கொள்ளுங்கள்\")\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁தமிழ்', '▁மொழி', '▁பற்றி', '▁அறிந்து', '▁கொள்ள', 'ுங்கள்']\n"
     ]
    }
   ],
   "source": [
    "print([sp.id_to_piece(idx) for idx in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "தமிழ் மொழி பற்றி அறிந்து கொள்ளுங்கள்\n"
     ]
    }
   ],
   "source": [
    "text = sp.decode(ids)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
